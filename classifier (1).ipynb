{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25c3734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in c:\\anaconda\\lib\\site-packages (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\anaconda\\lib\\site-packages (from mlxtend) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\anaconda\\lib\\site-packages (from mlxtend) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\anaconda\\lib\\site-packages (from mlxtend) (2.0.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\anaconda\\lib\\site-packages (from mlxtend) (1.3.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\anaconda\\lib\\site-packages (from mlxtend) (3.7.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\anaconda\\lib\\site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.3.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\anaconda\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9cb0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def generate_candidates(itemsets, length):\n",
    "    return [i.union(j) for i in itemsets for j in itemsets if len(i.union(j)) == length]\n",
    "\n",
    "def frequent_itemsets(transactions, min_support):\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    num_transactions = len(transactions)\n",
    "    frequent_items = {item for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    frequent_itemsets = [{item} for item in frequent_items]\n",
    "    k = 2\n",
    "    while True:\n",
    "        candidate_itemsets = generate_candidates(frequent_itemsets, k)\n",
    "        item_counts = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for itemset in candidate_itemsets:\n",
    "                if itemset.issubset(transaction):\n",
    "                    item_counts[frozenset(itemset)] += 1\n",
    "\n",
    "        frequent_itemsets = {itemset for itemset, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "        if len(frequent_itemsets) == 0:\n",
    "            break\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for itemset in frequent_itemsets:\n",
    "        if len(itemset) > 1:\n",
    "            for i in range(1, len(itemset)):\n",
    "                for antecedent in combinations(itemset, i):\n",
    "                    antecedent = set(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    confidence = len(frequent_itemsets[itemset]) / len(frequent_itemsets[antecedent])\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append((antecedent, consequent, confidence))\n",
    "    return rules\n",
    "\n",
    "def print_rules(rules):\n",
    "    for antecedent, consequent, confidence in rules:\n",
    "        print(f\"{antecedent} -> {consequent} : {confidence}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transactions = [\n",
    "        {'Milk', 'Bread', 'Diapers'},\n",
    "        {'Milk', 'Beer'},\n",
    "        {'Bread', 'Diapers', 'Eggs'},\n",
    "        {'Milk', 'Bread', 'Diapers', 'Beer'},\n",
    "        {'Bread', 'Eggs'}\n",
    "    ]\n",
    "    min_support = 0.4\n",
    "    min_confidence = 0.7\n",
    "\n",
    "    frequent_itemsets = frequent_itemsets(transactions, min_support)\n",
    "    rules = generate_rules(frequent_itemsets, min_confidence)\n",
    "    print_rules(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b668ddcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss:0.2603934560779369\n",
      "Epoch 4000, Loss:0.007447678117625393\n",
      "Epoch 8000, Loss:0.00241314167638002\n",
      "Predictions after training:\n",
      "[[0.04303867]\n",
      " [0.95432855]\n",
      " [0.95861694]\n",
      " [0.03774196]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "  \n",
    "class NeuralNetwork: \n",
    "    def __init__(self, input_size, hidden_size, output_size): \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size \n",
    "  \n",
    "        # Initialize weights \n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) \n",
    "  \n",
    "        # Initialize the biases \n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size)) \n",
    "        self.bias_output = np.zeros((1, self.output_size)) \n",
    "  \n",
    "    def sigmoid(self, x): \n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "  \n",
    "    def sigmoid_derivative(self, x): \n",
    "        return x * (1 - x) \n",
    "  \n",
    "    def feedforward(self, X): \n",
    "        # Input to hidden \n",
    "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden \n",
    "        self.hidden_output = self.sigmoid(self.hidden_activation) \n",
    "  \n",
    "        # Hidden to output \n",
    "        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output \n",
    "        self.predicted_output = self.sigmoid(self.output_activation) \n",
    "  \n",
    "        return self.predicted_output \n",
    "  \n",
    "    def backward(self, X, y, learning_rate): \n",
    "        # Compute the output layer error \n",
    "        output_error = y - self.predicted_output \n",
    "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output) \n",
    "  \n",
    "        # Compute the hidden layer error \n",
    "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T) \n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output) \n",
    "  \n",
    "        # Update weights and biases \n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate \n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate \n",
    "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate \n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate \n",
    "  \n",
    "    def train(self, X, y, epochs, learning_rate): \n",
    "        for epoch in range(epochs): \n",
    "            output = self.feedforward(X) \n",
    "            self.backward(X, y, learning_rate) \n",
    "            if epoch % 4000 == 0: \n",
    "                loss = np.mean(np.square(y - output)) \n",
    "                print(f\"Epoch {epoch}, Loss:{loss}\") \n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \n",
    "y = np.array([[0], [1], [1], [0]]) \n",
    "  \n",
    "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1) \n",
    "nn.train(X, y, epochs=10000, learning_rate=0.1) \n",
    "  \n",
    "# Test the trained model \n",
    "output = nn.feedforward(X) \n",
    "print(\"Predictions after training:\") \n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b3d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss:0.27818219216085655\n",
      "Epoch 4000, Loss:0.010794022114644567\n",
      "Epoch 8000, Loss:0.0024804841329146353\n",
      "Predictions after training:\n",
      "[[0.02595402]\n",
      " [0.95844795]\n",
      " [0.9573997 ]\n",
      " [0.05185008]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "  \n",
    "class NeuralNetwork: \n",
    "    def __init__(self, input_size, hidden_size, output_size): \n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size \n",
    "        self.output_size = output_size \n",
    "  \n",
    "        # Initialize weights \n",
    "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) \n",
    "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) \n",
    "  \n",
    "        # Initialize the biases \n",
    "        self.bias_hidden = np.zeros((1, self.hidden_size)) \n",
    "        self.bias_output = np.zeros((1, self.output_size)) \n",
    "  \n",
    "    def sigmoid(self, x): \n",
    "        return 1 / (1 + np.exp(-x)) \n",
    "  \n",
    "    def sigmoid_derivative(self, x): \n",
    "        return x * (1 - x) \n",
    "  \n",
    "    def feedforward(self, X): \n",
    "        # Input to hidden \n",
    "        self.hidden_activation = np.dot(X, self.weights_input_hidden) + self.bias_hidden \n",
    "        self.hidden_output = self.sigmoid(self.hidden_activation) \n",
    "  \n",
    "        # Hidden to output \n",
    "        self.output_activation = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output \n",
    "        self.predicted_output = self.sigmoid(self.output_activation) \n",
    "  \n",
    "        return self.predicted_output \n",
    "  \n",
    "    def backward(self, X, y, learning_rate): \n",
    "        # Compute the output layer error \n",
    "        output_error = y - self.predicted_output \n",
    "        output_delta = output_error * self.sigmoid_derivative(self.predicted_output) \n",
    "  \n",
    "        # Compute the hidden layer error \n",
    "        hidden_error = np.dot(output_delta, self.weights_hidden_output.T) \n",
    "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output) \n",
    "  \n",
    "        # Update weights and biases \n",
    "        self.weights_hidden_output += np.dot(self.hidden_output.T, output_delta) * learning_rate \n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate \n",
    "        self.weights_input_hidden += np.dot(X.T, hidden_delta) * learning_rate \n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate \n",
    "  \n",
    "    def train(self, X, y, epochs, learning_rate): \n",
    "        for epoch in range(epochs): \n",
    "            output = self.feedforward(X) \n",
    "            self.backward(X, y, learning_rate) \n",
    "            if epoch % 4000 == 0: \n",
    "                loss = np.mean(np.square(y - output)) \n",
    "                print(f\"Epoch {epoch}, Loss:{loss}\") \n",
    "  \n",
    "    def update_dataset(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        \n",
    "# Example usage:\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]) \n",
    "y = np.array([[0], [1], [1], [0]]) \n",
    "  \n",
    "nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1) \n",
    "nn.update_dataset(X, y)  # Update the dataset\n",
    "\n",
    "nn.train(X, y, epochs=10000, learning_rate=0.1) \n",
    "  \n",
    "# Test the trained model \n",
    "output = nn.feedforward(X) \n",
    "print(\"Predictions after training:\") \n",
    "print(output) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35eab6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of samples: 3\n",
      "Enter the y values separated by spaces: 0 1 0\n",
      "Enter the left split values for sample 1 separated by spaces: 0\n",
      "Enter the right split values for sample 1 separated by spaces: 1 0\n",
      "Enter the left split values for sample 2 separated by spaces: 1\n",
      "Enter the right split values for sample 2 separated by spaces: 0\n",
      "Enter the left split values for sample 3 separated by spaces: 0 1\n",
      "Enter the right split values for sample 3 separated by spaces: 1\n",
      "\n",
      "For split 1:\n",
      "Information Gain: 0.2516291673878229\n",
      "Gini Gain: 0.1111111111111111\n",
      "\n",
      "For split 2:\n",
      "Information Gain: 0.9182958340544896\n",
      "Gini Gain: 0.4444444444444444\n",
      "\n",
      "For split 3:\n",
      "Information Gain: 0.2516291673878229\n",
      "Gini Gain: 0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def information_gain(y, split):\n",
    "    original_entropy = entropy(y)\n",
    "    left_split, right_split = split\n",
    "    left_entropy = entropy(left_split)\n",
    "    right_entropy = entropy(right_split)\n",
    "    return original_entropy - (len(left_split) / len(y) * left_entropy + len(right_split) / len(y) * right_entropy)\n",
    "\n",
    "def gini_index(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "def gini_gain(y, split):\n",
    "    original_gini = gini_index(y)\n",
    "    left_split, right_split = split\n",
    "    left_gini = gini_index(left_split)\n",
    "    right_gini = gini_index(right_split)\n",
    "    return original_gini - (len(left_split) / len(y) * left_gini + len(right_split) / len(y) * right_gini)\n",
    "\n",
    "# Accepting user input for the dataset\n",
    "num_samples = int(input(\"Enter the number of samples: \"))\n",
    "y_values = input(\"Enter the y values separated by spaces: \").split()\n",
    "y = np.array(y_values, dtype=int)\n",
    "\n",
    "splits = []\n",
    "for i in range(num_samples):\n",
    "    left_values = input(f\"Enter the left split values for sample {i+1} separated by spaces: \").split()\n",
    "    right_values = input(f\"Enter the right split values for sample {i+1} separated by spaces: \").split()\n",
    "    left_split = np.array(left_values, dtype=int)\n",
    "    right_split = np.array(right_values, dtype=int)\n",
    "    splits.append((left_split, right_split))\n",
    "\n",
    "# Calculating attribute selection measures\n",
    "for i, split in enumerate(splits):\n",
    "    print(f\"\\nFor split {i+1}:\")\n",
    "    print(\"Information Gain:\", information_gain(y, split))\n",
    "    print(\"Gini Gain:\", gini_gain(y, split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c074fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain: -0.07864881038633575\n",
      "Gini Gain: -0.03125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "def information_gain(y, split):\n",
    "    original_entropy = entropy(y)\n",
    "    left_split, right_split = split\n",
    "    left_entropy = entropy(left_split)\n",
    "    right_entropy = entropy(right_split)\n",
    "    return original_entropy - (len(left_split) / len(y) * left_entropy + len(right_split) / len(y) * right_entropy)\n",
    "\n",
    "def gini_index(y):\n",
    "    _, counts = np.unique(y, return_counts=True)\n",
    "    probabilities = counts / len(y)\n",
    "    return 1 - np.sum(probabilities ** 2)\n",
    "\n",
    "def gini_gain(y, split):\n",
    "    original_gini = gini_index(y)\n",
    "    left_split, right_split = split\n",
    "    left_gini = gini_index(left_split)\n",
    "    right_gini = gini_index(right_split)\n",
    "    return original_gini - (len(left_split) / len(y) * left_gini + len(right_split) / len(y) * right_gini)\n",
    "\n",
    "# Example usage:\n",
    "y = np.array([0, 0, 1, 1, 0, 1, 1, 1])\n",
    "split = (np.array([0, 1, 1]), np.array([0, 1, 1, 0, 1, 1]))\n",
    "print(\"Information Gain:\", information_gain(y, split))\n",
    "print(\"Gini Gain:\", gini_gain(y, split))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebcc17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
